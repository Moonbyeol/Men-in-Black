{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a63c51-cee2-4350-8b06-b319cce7e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53fbc0f-8cd5-4128-9cd9-1c2ed0f234c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://844c9be6c168adcff9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://844c9be6c168adcff9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189], \n",
    "        [0.349, 0.686, 0.168], \n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(), \"image\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de66d3ba-0fbd-42fa-b7a1-4e9bc4980ff1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zoedepth.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzoedepth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradio_depth_pred\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_demo \u001b[38;5;28;01mas\u001b[39;00m create_depth_pred_demo\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_im_to_3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_demo \u001b[38;5;28;01mas\u001b[39;00m create_im_to_3d_demo\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_pano_to_3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_demo \u001b[38;5;28;01mas\u001b[39;00m create_pano_to_3d_demo\n",
      "File \u001b[0;32m/content/Men-in-Black/gradio/zoedepth/gradio_depth_pred.py:26\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MIT License\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022 Intelligent Systems Lab Org\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# File author: Shariq Farooq Bhat\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzoedepth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colorize\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'zoedepth.utils'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "\n",
    "from zoedepth.gradio_depth_pred import create_demo as create_depth_pred_demo\n",
    "from gradio_im_to_3d import create_demo as create_im_to_3d_demo\n",
    "from gradio_pano_to_3d import create_demo as create_pano_to_3d_demo\n",
    "\n",
    "\n",
    "css = \"\"\"\n",
    "#img-display-container {\n",
    "    max-height: 50vh;\n",
    "    }\n",
    "#img-display-input {\n",
    "    max-height: 40vh;\n",
    "    }\n",
    "#img-display-output {\n",
    "    max-height: 40vh;\n",
    "    }\n",
    "    \n",
    "\"\"\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.hub.load('isl-org/ZoeDepth', \"ZoeD_NK\", pretrained=True).to(DEVICE).eval()\n",
    "\n",
    "title = \"# ZoeDepth\"\n",
    "description = \"\"\"Official demo for **ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth**.\n",
    "\n",
    "ZoeDepth is a deep learning model for metric depth estimation from a single image.\n",
    "\n",
    "Please refer to our [paper](https://arxiv.org/abs/2302.12288) or [github](https://github.com/isl-org/ZoeDepth) for more details.\"\"\"\n",
    "\n",
    "with gr.Blocks(css=css) as demo:\n",
    "    gr.Markdown(title)\n",
    "    gr.Markdown(description)\n",
    "    with gr.Tab(\"Depth Prediction\"):\n",
    "        create_depth_pred_demo(model)\n",
    "    with gr.Tab(\"Image to 3D\"):\n",
    "        create_im_to_3d_demo(model)\n",
    "    with gr.Tab(\"360 Panorama to 3D\"):\n",
    "        create_pano_to_3d_demo(model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22b4248a-b4a1-497a-91df-d4b0643ba001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/Men-in-Black/gradio', '/home/ubuntu/anaconda3/lib/python310.zip', '/home/ubuntu/anaconda3/lib/python3.10', '/home/ubuntu/anaconda3/lib/python3.10/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.10/site-packages', '/home/ubuntu/anaconda3/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg', '/home/ubuntu/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg', '/content/Men-in-Black/gradio/zoedepth', '/content/Men-in-Black/Monocular Depth Estimation/ZoeDepth/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25f8079-0cc6-4ae1-8caa-6e5cfd99ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/content/Men-in-Black/Monocular Depth Estimation/ZoeDepth/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1ffa7-720a-4271-a307-8ac67902baae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
