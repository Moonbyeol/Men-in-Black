{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea13a3ff-b08a-48b0-a3f9-2f4d31714b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size [384, 512]\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 motorcycle, 2 trucks, 1 traffic light, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/isl-org_ZoeDepth_main\n",
      "Using cache found in /home/ubuntu/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 motorcycle, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 3 traffic lights, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 motorcycle, 1 bus, 2 trucks, 4 traffic lights, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 2 motorcycles, 2 trucks, 2 traffic lights, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 motorcycle, 2 trucks, 2 traffic lights, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 1 motorcycle, 2 trucks, 3 traffic lights, 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Params passed to Resize transform:\n",
      "\twidth:  512\n",
      "\theight:  384\n",
      "\tresize_target:  True\n",
      "\tkeep_aspect_ratio:  True\n",
      "\tensure_multiple_of:  32\n",
      "\tresize_method:  minimal\n",
      "Using pretrained resource url::https://github.com/isl-org/ZoeDepth/releases/download/v1.0/ZoeD_M12_NK.pt\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 motorcycle, 1 truck, 3 traffic lights, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Loaded successfully\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 motorcycle, 1 truck, 3 traffic lights, 15.6ms\n",
      "Speed: 2.9ms preprocess, 15.6ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 1 motorcycle, 1 truck, 2 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 motorcycle, 1 truck, 2 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Running on public URL: https://5ccbcbd1bf7d643256.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5ccbcbd1bf7d643256.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 motorcycle, 1 truck, 2 traffic lights, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 1 motorcycle, 1 truck, 3 traffic lights, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 1 motorcycle, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 motorcycle, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 1 motorcycle, 1 truck, 4 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 motorcycle, 1 truck, 4 traffic lights, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 motorcycle, 1 bus, 1 truck, 4 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 motorcycle, 2 buss, 2 trucks, 4 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 9 cars, 1 motorcycle, 1 bus, 1 truck, 4 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 1 motorcycle, 1 truck, 5 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 1 motorcycle, 3 traffic lights, 1 handbag, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 motorcycle, 1 truck, 3 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 384x640 3 persons, 8 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 12.8ms\n",
      "Speed: 1.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 480x640 3 cars, 1 truck, 299.3ms\n",
      "Speed: 2.4ms preprocess, 299.3ms inference, 32.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Error during video processing: unflatten: Provided sizes [24, 42] don't multiply up to the size of dim 2 (768) in the input tensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.10/site-packages/gradio/queueing.py\", line 489, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.10/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1542, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1369, in postprocess_data\n",
      "    self.validate_outputs(fn_index, predictions)  # type: ignore\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1343, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: An event handler didn't receive enough output values (needed: 4, received: 0).\n",
      "Wanted outputs:\n",
      "    [video, video, video, video]\n",
      "Received outputs:\n",
      "    []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 13 cars, 1 bus, 1 truck, 4 traffic lights, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x69637661/'avci' is not found (format 'mp4 / MP4 (MPEG-4 Part 14)')'\n",
      "OpenCV: FFMPEG: tag 0x69637661/'avci' is not found (format 'mp4 / MP4 (MPEG-4 Part 14)')'\n",
      "OpenCV: FFMPEG: tag 0x69637661/'avci' is not found (format 'mp4 / MP4 (MPEG-4 Part 14)')'\n",
      "OpenCV: FFMPEG: tag 0x69637661/'avci' is not found (format 'mp4 / MP4 (MPEG-4 Part 14)')'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 11 cars, 2 buss, 2 trucks, 4 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12 cars, 1 bus, 2 trucks, 4 traffic lights, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 4 traffic lights, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 2 trucks, 4 traffic lights, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 2 buss, 2 trucks, 2 traffic lights, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 2 buss, 1 truck, 2 traffic lights, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 2 trucks, 2 traffic lights, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 2 buss, 1 truck, 1 traffic light, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 1 traffic light, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 2 buss, 1 truck, 2 traffic lights, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 2 buss, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 4 buss, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 buss, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 buss, 1 truck, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 2 buss, 1 truck, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 bus, 2 trucks, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 bus, 1 truck, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 1 truck, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 1 traffic light, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 1 truck, 1 traffic light, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from gradio_files.zoedepth.gradio_depth_pred import create_demo as create_depth_pred_demo\n",
    "from gradio_files.zoedepth.gradio_im_to_3d import create_demo as create_im_to_3d_demo\n",
    "from gradio_files.zoedepth.gradio_pano_to_3d import create_demo as create_pano_to_3d_demo\n",
    "from gradio_files.zoedepth.gradio_depth_pred_video import create_demo as create_depth_pred_demo_video\n",
    "import torch\n",
    "\n",
    "# Load ZoeDepth Model\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "depth_model = torch.hub.load('isl-org/ZoeDepth', \"ZoeD_NK\", pretrained=True).to(DEVICE).eval()\n",
    "\n",
    "def update(name):\n",
    "    return f\"Welcome to Gradio, {name}!\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Image Depth Prediction\"):\n",
    "        create_depth_pred_demo(depth_model)\n",
    "    with gr.Tab(\"Video Depth Prediction\"):\n",
    "        create_depth_pred_demo_video(depth_model)\n",
    "    with gr.Tab(\"Image to 3D\"):\n",
    "        create_im_to_3d_demo(depth_model)\n",
    "    with gr.Tab(\"360 Panorama to 3D\"):\n",
    "        create_pano_to_3d_demo(depth_model)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c61f7a-13d2-4010-b3ca-6b12dc1b7b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
